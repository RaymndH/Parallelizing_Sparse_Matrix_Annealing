{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxtVFPihOZS2EuA9HhA+kX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaymndH/Parallelizing_Sparse_Matrix_Annealing/blob/main/Sparse_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import networkx as nx\n",
        "import random\n",
        "\n",
        "matrixpath = \"N-1e3_c-18.0_q-5\""
      ],
      "metadata": {
        "id": "1ARt8w0pdb5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qa9jjRKTJMR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def read_graph_txt(path, device):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    N = int(lines[0])\n",
        "    edges = [tuple(map(int, line.strip().split())) for line in lines[1:]]\n",
        "\n",
        "    # Build edge index lists\n",
        "    row_list, col_list = zip(*edges)\n",
        "\n",
        "    # Duplicate for symmetric edges\n",
        "    row = torch.tensor(list(row_list) + list(col_list), dtype=torch.long)\n",
        "    col = torch.tensor(list(col_list) + list(row_list), dtype=torch.long)\n",
        "\n",
        "    values = torch.ones(len(row), dtype=torch.float32)\n",
        "    coords = torch.stack([row, col], dim=0).to(device)\n",
        "    values = values.to(device)\n",
        "\n",
        "    return N, coords, values, edges\n",
        "\n",
        "def iterative_mis_peeling(G, target_frac=0.1):\n",
        "    total_nodes = G.number_of_nodes()\n",
        "    remaining = set(G.nodes())\n",
        "    mis_list = []\n",
        "    G_sub = G.copy()\n",
        "\n",
        "    while len(remaining) > total_nodes * target_frac:\n",
        "        mis = nx.algorithms.mis.maximal_independent_set(G_sub)\n",
        "        mis_set = set(mis)\n",
        "        mis_list.append(mis_set)\n",
        "        G_sub.remove_nodes_from(mis_set)\n",
        "        remaining -= mis_set\n",
        "    return mis_list, remaining\n",
        "\n",
        "def compute_energy(q_idx, Aq):\n",
        "    row_idx = torch.arange(q_idx.shape[0], device=q_idx.device)\n",
        "    return Aq[row_idx, q_idx].sum().item()"
      ],
      "metadata": {
        "id": "muZnG-3oQxt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Parameters ===\n",
        "num_classes = 5\n",
        "T = 1.5\n",
        "dT = 1e-5\n",
        "min_T = 1e-4\n",
        "max_epochs = 100000000\n",
        "file_path = 'N-1e3_c-18.0_q-5'  # Update with your actual path\n",
        "\n",
        "# === Setup ===\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "N, coords, values, edge_list = read_graph_txt(file_path, device)\n",
        "A = torch.sparse_coo_tensor(coords, values, (N, N)).coalesce()\n",
        "\n",
        "# Build NetworkX graph\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edge_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "ypv8Qf49dPHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute MIS sets once\n",
        "mislists=[]\n",
        "for i in range(10):\n",
        "  mis_list, leftover = iterative_mis_peeling(G, target_frac=0.0)\n",
        "  mislists.append(mis_list)\n",
        "print(f\"Computed {len(mislists)} MIS sets\")\n",
        "\n",
        "row_idx = torch.arange(N, device=device)\n",
        "q_idx = torch.randint(0, num_classes, (N,), device=device)\n",
        "\n",
        "\n",
        "\n",
        "# Initial energy\n",
        "q_onehot = torch.nn.functional.one_hot(q_idx, num_classes=num_classes).float().to(device)\n",
        "Aq = torch.sparse.mm(A, q_onehot)\n",
        "initial_energy = compute_energy(q_idx, Aq)\n",
        "print(f\"Initial system energy: {initial_energy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OiEZz1nwYoM",
        "outputId": "ee0e505b-49cd-44d9-8ea6-a911ced6c4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed 10 MIS sets\n",
            "Initial system energy: 3564.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGFYHTDPhrb-",
        "outputId": "f785a98a-6ef2-4cce-8c03-749c4a465c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = []\n",
        "for i in range(len(G)):\n",
        "  v = set()\n"
      ],
      "metadata": {
        "id": "2g4C4YoIhZCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_energy(q_idx, Aq))\n",
        "torch.cuda.synchronize()\n",
        "start_evt = torch.cuda.Event(enable_timing=True)\n",
        "end_evt = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start_evt.record()\n",
        "\n",
        "for i, node in enumerate(q_onehot):\n",
        "  color = q_idx[i]\n",
        "  altcolor = (color + torch.randint(1, num_classes, (1,), device=device)) % num_classes\n",
        "  de = Aq[i][altcolor] - Aq[i][q_idx[i]]\n",
        "  #if (i == 0): print(de)\n",
        "  if de < 0:\n",
        "    #if (i==0): print(\"yes\")\n",
        "    #if (i==0): print(\"qidx before:\", q_idx[i])\n",
        "    Aq[rows, color] -= 1\n",
        "    Aq[rows, altcolor] += 1\n",
        "    q_idx[i] = altcolor\n",
        "    #if (i==0): print(\"qidx after:\", q_idx[i])\n",
        "end_evt.record()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_ms = start_evt.elapsed_time(end_evt)\n",
        "print(elapsed_ms)\n",
        "\n",
        "print(compute_energy(q_idx, Aq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "EporrpfYdYHV",
        "outputId": "510cfdd1-2902-402d-aebd-0dbb14480b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360504.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'rows' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2508313453.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#if (i==0): print(\"yes\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#if (i==0): print(\"qidx before:\", q_idx[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mAq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mAq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltcolor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mq_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_time_ms = 0.0\n",
        "dT = 1e-3\n",
        "T = 1.4\n",
        "min_T = 0\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_updates = 0\n",
        "    epoch_time_ms = 0.0\n",
        "\n",
        "    for i, mis_nodes in enumerate(random.choice(mislists)):\n",
        "        mis_mask = torch.zeros(N, dtype=torch.bool, device=device) # which nodes to use\n",
        "        mis_mask[list(mis_nodes)] = True\n",
        "\n",
        "        offsets = torch.randint(1, num_classes, (N,), device=device) # altcolor\n",
        "        q_hat_idx = (q_idx + offsets) % num_classes\n",
        "        q_hat_idx_sparse = q_hat_idx.clone()\n",
        "        q_hat_idx_sparse[~mis_mask] = -1\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        start_evt = torch.cuda.Event(enable_timing=True)\n",
        "        end_evt = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "        start_evt.record()\n",
        "\n",
        "        q_onehot = torch.nn.functional.one_hot(q_idx, num_classes=num_classes).float().to(device) # create q vector\n",
        "        Aq = torch.sparse.mm(A, q_onehot) #calc Aq\n",
        "\n",
        "        a_q = Aq[row_idx, q_idx] # energy with current color\n",
        "        a_q_hat = torch.zeros(N, device=device)\n",
        "        valid = q_hat_idx_sparse != -1\n",
        "        a_q_hat[valid] = Aq[row_idx[valid], q_hat_idx_sparse[valid]]\n",
        "\n",
        "        v = a_q_hat - a_q # de\n",
        "        candidate_mask =  valid & mis_mask # which to flip (this is probably wrong)\n",
        "        num_candidates = candidate_mask.sum().item() # how many flipping?\n",
        "\n",
        "        if num_candidates > 0:\n",
        "            v_candidates = v[candidate_mask] #get all energies\n",
        "            r = torch.rand(num_candidates, device=device) # prn\n",
        "            acceptance_prob = torch.exp(-v_candidates / T) #\n",
        "            accept_mask = acceptance_prob > r # which to flip\n",
        "\n",
        "            full_accept_mask = torch.zeros_like(candidate_mask, dtype=torch.bool) #\n",
        "            full_accept_mask[candidate_mask] = accept_mask #the candidates which are accepted go yes.\n",
        "\n",
        "            q_idx[full_accept_mask] = q_hat_idx_sparse[full_accept_mask] # qs are flipped\n",
        "            updated_count = full_accept_mask.sum().item()\n",
        "        else:\n",
        "            updated_count = 0\n",
        "\n",
        "        #for site in remaining:\n",
        "          # if thing is < ln(r):\n",
        "            #\n",
        "\n",
        "\n",
        "        end_evt.record()\n",
        "        torch.cuda.synchronize()\n",
        "        elapsed_ms = start_evt.elapsed_time(end_evt)\n",
        "\n",
        "        epoch_time_ms += elapsed_ms\n",
        "        epoch_updates += updated_count\n",
        "\n",
        "        #print(f\"  MIS {i+1}: {elapsed_ms:.3f} ms, Updates: {updated_count}\")\n",
        "\n",
        "    if epoch%10 == 0:\n",
        "      print(f\"\\r epoch {epoch} of {int(1.4/dT)} done:\",\n",
        "            f\"Temperature = {T:.6f},\",\n",
        "            f\"Time = {epoch_time_ms:.3f} ms,\",\n",
        "            f\"Total updates = {epoch_updates},\",\n",
        "            f\"energy = {compute_energy(q_idx, Aq)}\",\n",
        "            \"                     \",end=\"\", sep=\" \")\n",
        "    #print()\n",
        "    total_time_ms += epoch_time_ms\n",
        "\n",
        "    T = max(min_T, T - dT)\n",
        "    if T <= min_T:\n",
        "        print(\"Minimum temperature reached.\")\n",
        "        break\n",
        "\n",
        "# Final energy\n",
        "q_onehot = torch.nn.functional.one_hot(q_idx, num_classes=num_classes).float().to(device)\n",
        "Aq = torch.sparse.mm(A, q_onehot)\n",
        "final_energy = compute_energy(q_idx, Aq)\n",
        "\n",
        "print(f\"\\nFinal system energy: {final_energy:.4f}\")\n",
        "print(f\"Initial energy:       {initial_energy:.4f}\")\n",
        "print(f\"Energy change:        {final_energy - initial_energy:.4f}\")\n",
        "print(f\"Total annealing time: {total_time_ms:.3f} ms over {epoch+1} epochs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ri-vs6Q82b",
        "outputId": "918e41b0-ca8a-4796-d280-f0b12be1d4aa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch 1400 of 1399 done: Temperature = 0.000000, Time = 10.165 ms, Total updates = 14, energy = 370.0                      Minimum temperature reached.\n",
            "\n",
            "Final system energy: 370.0000\n",
            "Initial energy:       3564.0000\n",
            "Energy change:        -3194.0000\n",
            "Total annealing time: 15371.228 ms over 1401 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"\\rthis one is {i}\",end=\"\")\n",
        "  time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_083eYnLIgi-",
        "outputId": "13c9bdd2-84b5-4c70-cac6-143fe435b7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this one is 9"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v[mylist[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4d_nT0a5r90",
        "outputId": "d3b53d0f-d24d-4809-dd0f-233b49cd1599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_q_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSvSrzMP5vQU",
        "outputId": "8c35a0a6-ee0d-434d-d3bf-45d6583ed223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  5.,  0.,  5.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  4.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  2.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  4.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  4.,  4.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  5.,\n",
              "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,  0.,  3.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  7.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  5.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,\n",
              "         5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         2.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  6.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,\n",
              "         0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         4.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_q[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Z3eG8h7Lpr",
        "outputId": "863ca5e8-920a-4259-af55-a0e371a1a12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}